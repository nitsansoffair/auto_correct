{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitsansoffair/auto_correct/blob/master/auto_correct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xaYdnI4Ervr"
      },
      "source": [
        "# Autocorrect"
      ],
      "id": "9xaYdnI4Ervr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msI1TsfkErvx"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from numpy import unique\n",
        "import pandas as pd\n",
        "import os\n",
        "import w1_unittest"
      ],
      "id": "msI1TsfkErvx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIOuWC3eErwA"
      },
      "source": [
        "#### Process text to words array without punctuations."
      ],
      "id": "PIOuWC3eErwA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J5lWE-LErwK"
      },
      "outputs": [],
      "source": [
        "def process_data(file_name):\n",
        "    words = []\n",
        "    file = open(f\"./data/shakespeare.txt\", \"r\")\n",
        "    content = file.read()\n",
        "    content_lower = content.lower()\n",
        "    lines = content_lower.split('\\n')\n",
        "    for line in lines:\n",
        "        words_line = line.split(' ')\n",
        "        for word_line in words_line:\n",
        "            letters_only = re.sub(\"[^A-Za-z0-9]+\", \"\", word_line)\n",
        "            if len(letters_only) > 0:\n",
        "                words.append(letters_only)\n",
        "    return words"
      ],
      "id": "6J5lWE-LErwK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtOzphDyErwM",
        "outputId": "7f67437e-3348-4f0d-d38c-4b104be948d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first ten words in the text are: \n",
            "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6457 unique words in the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "word_l = process_data('./data/shakespeare.txt')\n",
        "vocab = set(word_l)\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "id": "jtOzphDyErwM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNuUUUfbErwO"
      },
      "source": [
        "#### Count total shows for each words."
      ],
      "id": "MNuUUUfbErwO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub8GYmZCErwO"
      },
      "outputs": [],
      "source": [
        "def get_count(word_l):\n",
        "    word_count_dict = {} \n",
        "    for word in word_l:\n",
        "        if word in word_count_dict.keys():\n",
        "            word_count_dict[word] += 1\n",
        "        else:\n",
        "            word_count_dict[word] = 1\n",
        "    return word_count_dict"
      ],
      "id": "ub8GYmZCErwO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJmhPqD_ErwP",
        "outputId": "17bad628-6665-4121-d49f-9a6787af2c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 6457 key values pairs\n",
            "The count for the word 'thee' is 240\n"
          ]
        }
      ],
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
        "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
      ],
      "id": "ZJmhPqD_ErwP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnf6evPBErwS"
      },
      "source": [
        "#### Calculate word probability for each word."
      ],
      "id": "Hnf6evPBErwS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61uxPX6oErwT"
      },
      "outputs": [],
      "source": [
        "def get_probs(word_count_dict):\n",
        "    probs = {}\n",
        "    for word in word_count_dict.keys():\n",
        "        probs[word] = word_count_dict[word] / np.sum(list(word_count_dict.values()))\n",
        "    return probs"
      ],
      "id": "61uxPX6oErwT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXj-Jb6HErwT",
        "outputId": "feb2e6e6-ddd0-48aa-dda8-bf7a72957856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of probs is 6457\n",
            "P('thee') is 0.0046\n"
          ]
        }
      ],
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['thee']:.4f}\")"
      ],
      "id": "XXj-Jb6HErwT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COXYPcpBErwU"
      },
      "source": [
        "#### Delete letter on word procedure."
      ],
      "id": "COXYPcpBErwU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh0z-_K2ErwV"
      },
      "outputs": [],
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    delete_l = []\n",
        "    for index in range(len(word)):\n",
        "        delete_l.append(word[:index] + word[index + 1:])\n",
        "    return delete_l"
      ],
      "id": "Xh0z-_K2ErwV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3cwgB0FErwV"
      },
      "outputs": [],
      "source": [
        "delete_word_l = delete_letter(word=\"cans\", verbose=True)"
      ],
      "id": "L3cwgB0FErwV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfIfTiAkErwW",
        "outputId": "128f2ee6-2099-4448-e2da-2d3fa291ff4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of outputs of delete_letter('at') is 2\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
      ],
      "id": "RfIfTiAkErwW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8KWy1IGErwc"
      },
      "source": [
        "#### Switch two follows letters on word procedure."
      ],
      "id": "O8KWy1IGErwc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aljegb6PErwd"
      },
      "outputs": [],
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    switch_l = []\n",
        "    for index in range(len(word) - 1):\n",
        "        switch_l.append(word[:index] + word[index + 1] + word[index] + word[index + 2:])\n",
        "    return switch_l"
      ],
      "id": "Aljegb6PErwd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7VGyPv5Erwe"
      },
      "outputs": [],
      "source": [
        "switch_word_l = switch_letter(word=\"eta\", verbose=True)"
      ],
      "id": "O7VGyPv5Erwe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5q06V6IErwf",
        "outputId": "de643544-0c55-4bde-8e4b-b524dd94b894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of outputs of switch_letter('at') is 1\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
      ],
      "id": "H5q06V6IErwf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY_i4jvDErwg"
      },
      "source": [
        "#### Replace letter on word procedure."
      ],
      "id": "uY_i4jvDErwg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9foKK-QErwh"
      },
      "outputs": [],
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_l = []\n",
        "    for index in range(len(word)):\n",
        "        for letter in letters:\n",
        "            word_replaced = word[:index] + letter + word[index + 1:]\n",
        "            if word_replaced not in replace_l + [word]:\n",
        "                replace_l.append(word_replaced)\n",
        "    return sorted(replace_l)"
      ],
      "id": "T9foKK-QErwh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYni6ZvKErwi"
      },
      "outputs": [],
      "source": [
        "replace_l = replace_letter(word='can', verbose=True)"
      ],
      "id": "fYni6ZvKErwi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8mz3wo8Erwi",
        "outputId": "82061b6c-b480-4afa-dd06-9017e295886c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of outputs of replace_letter('at') is 50\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
      ],
      "id": "B8mz3wo8Erwi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CCfqWI8Erwj"
      },
      "source": [
        "#### Insert letter to word procedure."
      ],
      "id": "3CCfqWI8Erwj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To5VuSheErwj"
      },
      "outputs": [],
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    for index in range(len(word) + 1):\n",
        "        for letter in letters:\n",
        "            insert_l.append(word[:index] + letter + word[index:])\n",
        "    return insert_l"
      ],
      "id": "To5VuSheErwj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPALzAI9Erwk",
        "outputId": "5a0a7884-cce7-4111-8ec5-b2a5dd8f1afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of strings output by insert_letter('at') is 78\n"
          ]
        }
      ],
      "source": [
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "id": "yPALzAI9Erwk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG-Nosz-Erwk"
      },
      "source": [
        "#### Edit one letter on word procedure."
      ],
      "id": "AG-Nosz-Erwk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsD_0tSYErwl"
      },
      "outputs": [],
      "source": [
        "def edit_one_letter(word, allow_switches=True):\n",
        "    return set(unique(insert_letter(word) + delete_letter(word) + replace_letter(word) + switch_letter(word)))"
      ],
      "id": "gsD_0tSYErwl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJlNkHIpErwl",
        "outputId": "b5a78696-4cb4-47e1-ff3a-9f7918e5a2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input word: at \n",
            "edit_one_l: \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ]
        }
      ],
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word: {tmp_word} \\nedit_one_l: \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "id": "fJlNkHIpErwl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyMw5DsPErwm"
      },
      "source": [
        "#### Edit two letters on word procedure."
      ],
      "id": "yyMw5DsPErwm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqXx1laLErwo"
      },
      "outputs": [],
      "source": [
        "def edit_two_letters(word, allow_switches=True):\n",
        "    edit_two_set = []\n",
        "    edit_one_set = edit_one_letter(word)\n",
        "    for word in edit_one_set:\n",
        "        edit_two_set += edit_one_letter(word)\n",
        "    return set(edit_two_set)"
      ],
      "id": "UqXx1laLErwo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IfnoZWzErwp"
      },
      "outputs": [],
      "source": [
        "def edit_n_letters(edit_set, word, n=1):\n",
        "    if n == 1:\n",
        "        return edit_one_letter(word)\n",
        "    edit_set_next = []\n",
        "    for edit_word in edit_set:\n",
        "        edit_set_next.append(edit_one_letter(edit_word))\n",
        "    return edit_n_letters(edit_set_next, word, n - 1)"
      ],
      "id": "2IfnoZWzErwp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIkcL8FAErwp",
        "outputId": "b1b0c780-75fb-4106-b4c4-e4fbff981a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "Number of strings that are 2 edit distances from 'at' is 7154\n"
          ]
        }
      ],
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
      ],
      "id": "bIkcL8FAErwp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCd-PXqwErwq"
      },
      "source": [
        "#### Get word corrections."
      ],
      "id": "qCd-PXqwErwq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GxayiEFErwq"
      },
      "outputs": [],
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose=False):\n",
        "    if word in vocab:\n",
        "        return [word]\n",
        "    edit_probs_total = {}\n",
        "    for edit_distance in range(1, n):\n",
        "        edit_probs = {edit_word: probs[edit_word] for edit_word in edit_n_letters([], word, n=edit_distance).intersection(vocab)}\n",
        "        edit_probs_total.update(edit_probs)\n",
        "    max_probs = sorted(list(edit_probs_total.values()))[len(edit_probs_total.values()) - n:]\n",
        "    edit_words = []\n",
        "    for index in range(len(edit_probs_total.keys())):\n",
        "        edit_word, edit_word_prob = list(edit_probs_total.keys())[index], list(edit_probs_total.values())[index]\n",
        "        if edit_word_prob in max_probs:\n",
        "            edit_words.append((edit_word, edit_word_prob))\n",
        "    return sorted(edit_words, key=lambda edit_tuple: edit_tuple[1], reverse=True)"
      ],
      "id": "9GxayiEFErwq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9BnrujtErwr",
        "outputId": "9a3a0789-2732-424b-bb4c-40980d70831c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word 0: days, probability 0.000422\n",
            "word 1: dye, probability 0.000019\n"
          ]
        }
      ],
      "source": [
        "my_word = 'dys' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
      ],
      "id": "X9BnrujtErwr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RoPRBEcErws"
      },
      "source": [
        "#### Get minimum edit distance."
      ],
      "id": "5RoPRBEcErws"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HywqFTGeErws"
      },
      "outputs": [],
      "source": [
        "def min_edit_distance(source, target, ins_cost=1, del_cost=1, rep_cost=2):\n",
        "    rows, columns = len(source), len(target)\n",
        "    distances = np.zeros((rows + 1, columns + 1), dtype=int)\n",
        "    for row in range(0, rows + 1):\n",
        "        distances[row, 0] = row * ins_cost\n",
        "    for column in range(0, columns + 1):\n",
        "        distances[0, column] = column * del_cost\n",
        "    for row in range(1, rows + 1):\n",
        "        for column in range(1, columns + 1):\n",
        "            r_cost = 0 if source[row - 1] == target[column - 1] else rep_cost\n",
        "            distances[row, column] = min(distances[row - 1, column - 1] + r_cost, distances[row - 1, column] + ins_cost, distances[row, column - 1] + del_cost)\n",
        "    return distances, distances[rows, columns]"
      ],
      "id": "HywqFTGeErws"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CccvjIKaErwt",
        "outputId": "26f22cdb-675f-4531-d962-3a3ca8b89738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "minimum edits:  4 \n",
            "\n",
            "   #  s  t  a  y\n",
            "#  0  1  2  3  4\n",
            "p  1  2  3  4  5\n",
            "l  2  3  4  5  6\n",
            "a  3  4  5  4  5\n",
            "y  4  5  6  5  4\n"
          ]
        }
      ],
      "source": [
        "source =  'play'\n",
        "target = 'stay'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list('#' + source)\n",
        "cols = list('#' + target)\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "id": "CccvjIKaErwt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BxcUTVAErwt",
        "outputId": "38b3364c-d7da-40d8-862c-85d81dc136e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "minimum edits:  3 \n",
            "\n",
            "   #  n  e  a  r\n",
            "#  0  1  2  3  4\n",
            "e  1  2  1  2  3\n",
            "e  2  3  2  3  4\n",
            "r  3  4  3  4  3\n"
          ]
        }
      ],
      "source": [
        "source =  'eer'\n",
        "target = 'near'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list(source)\n",
        "idx.insert(0, '#')\n",
        "cols = list(target)\n",
        "cols.insert(0, '#')\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "id": "3BxcUTVAErwt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9hLccF4Erwu"
      },
      "source": [
        "#### References\n",
        "- Coursera - Natural language processing with probabilistic models [course](https://www.coursera.org/learn/probabilistic-models-in-nlp)."
      ],
      "id": "b9hLccF4Erwu"
    }
  ],
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "auto_correct.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}